{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell # Nos permite mostar más de una salida por celda\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # Nos permite mostar más de una salida por celda\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volviendo a la documentación, la primera url que nos pone en la documentación es para sacar una frase de un personaje aleatorio de los simpson\n",
    "# para eso en la casilla en blanco que tenemos a la derecha nos muestra la url que deberemos usar. Por lo tanto, la copiamos y la metemos en una variable. La podemos llamar como queramos, en nuestro caso, la llamamos \"url\"\n",
    "url = 'https://thesimpsonsquoteapi.glitch.me/quotes'\n",
    "\n",
    "# hacemos la petición de los datos a la API\n",
    "response = requests.get(url=url)\n",
    "\n",
    "# pedimos a la API que nos diga si lo estamos haciendo bien con el método status_code\n",
    "response.status_code\n",
    "\n",
    "# le pedimos que nos diga el por qué\n",
    "response.reason\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos nuestro diccionario\n",
    "variable = {'count': 3}\n",
    "\n",
    "# añadimos a la petición el parámetro headers para añadir esa información que queríamos\n",
    "response = requests.get('https://thesimpsonsquoteapi.glitch.me/quotes', params=variable)\n",
    "\n",
    "# vemos si estamos haciendo bien la llamada:\n",
    "response.status_code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- EXTRAYENDO DATOS DE API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hagamoslo para la primera de las url que vimos de los simpsons, donde nos devolvía una frase aleatoria de un personaje aleatorio\n",
    "\n",
    "# establecemos la url a la que queremos hacer la llamada\n",
    "url = 'https://thesimpsonsquoteapi.glitch.me/quotes'\n",
    "\n",
    "# hacemos la llamada usando el método get\n",
    "response = requests.get(url=url)\n",
    "\n",
    "# almacenamos el resultado en una variable que se llama \"frase_json\" donde tendremos el json\n",
    "frase_json = response.json()\n",
    "\n",
    "# almacenamos el resultado en una variable que se llama \"frase_str\" donde tendremos el string\n",
    "frase_str = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vemoas otro ejemplo, en este caso con la llamada a la API con un número de frases concreto\n",
    "\n",
    "# definimos nuestro diccionario\n",
    "variable = {'count': \"3\"}\n",
    "\n",
    "# añadimos a la petición el parámetro headers para añadir esa información que queríamos\n",
    "response2 = requests.get(url=f'https://thesimpsonsquoteapi.glitch.me/quotes',params=variable)\n",
    "\n",
    "# vemos si estamos haciendo bien la llamada:\n",
    "response2.status_code\n",
    "\n",
    "\n",
    "maggie_df = pd.json_normalize(response2.json())\n",
    "maggie_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ALMACENANDO DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maggie_df.to_pickle('../files/API_simpsons.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LIBRERIA DATETIME"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ayer = datetime.now() - timedelta(1)\n",
    "ayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORMATEO FECHA \n",
    "ayer = datetime.strftime(ayer, '%Y-%m-%d')\n",
    "ayer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FUNCION ACTUALIZACION DATOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llamada_API(lat, lon, producto):\n",
    "    \n",
    "    # hacemos la llamada  a la API\n",
    "    url = f'http://www.7timer.info/bin/api.pl?lon=-{lon}&lat={lat}&product={producto}&output=json'\n",
    "\n",
    "    response = requests.get(url=url)\n",
    "    codigo_estado = response.status_code\n",
    "    razon_estado = response.reason\n",
    "    if codigo_estado == 200:\n",
    "        print('La peticion se ha realizado correctamente, se ha devuelto el código de estado:',codigo_estado,' y como razón del código de estado: ',razon_estado)\n",
    "    elif codigo_estado == 402:\n",
    "        print('No se ha podido autorizar usario, se ha devuelto el código de estado:', codigo_estado,' y como razón del código de estado: ',razon_estado)\n",
    "    elif codigo_estado == 404:\n",
    "        print('Algo ha salido mal, el recurso no se ha encontrado,se ha devuelto el código de estado:', codigo_estado,' y como razón del código de estado: ',razon_estado)\n",
    "    else:\n",
    "        print('Algo inesperado ha ocurrido, se ha devuelto el código de estado:', codigo_estado,' y como razón del código de estado: ',razon_estado)\n",
    "\n",
    "    # convertimos los resultados en un dataframe: \n",
    "    df = pd.DataFrame.from_dict(pd.json_normalize(response.json()['dataseries']))\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FUNCION LIMPIAR/AÑADIR DF NUEVOS DATOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_civil(df_nuevo, lat, long, ciudad): \n",
    "    \n",
    "    # lo primero que tenemos que hacer es crear la columna de fecha en el dataframe nuevo \n",
    "    # En este caso será la fecha del día de hoy. \n",
    "    hoy = datetime.now()\n",
    "    hoy = datetime.strftime(hoy, '%Y-%m-%d')\n",
    "    \n",
    "    # creamos la nueva columna\n",
    "    df_nuevo[\"fecha\"] = hoy\n",
    "    \n",
    "    df_nuevo[\"latitud\"] = lat\n",
    "    df_nuevo[\"longitud\"] = long\n",
    "    df_nuevo[\"ciudad\"] = ciudad\n",
    "    return df_nuevo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AÑADIENDO OTROS DATOS DE LA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la latitud y la longitud serán las mismas\n",
    "latitud = 40.4165\n",
    "longitud = -3.70256\n",
    "\n",
    "# pero en este caso el producto cambiará. En este caso \"astro\"\n",
    "producto2 = \"astro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llamamamos a la función \n",
    "\n",
    "df_astro = llamada_API(latitud, longitud, producto2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_astro(df, lat, long, ciudad):\n",
    "    \n",
    "    #seleccionamos solo las columnas que nos interesan\n",
    "    df = df[[\"seeing\", \"transparency\", \"timepoint\"]]\n",
    "    \n",
    "    # creamos la columna de fecha: \n",
    "    hoy = datetime.now()\n",
    "    hoy = datetime.strftime(hoy, '%Y-%m-%d')\n",
    "    df[\"fecha\"] = hoy\n",
    "    \n",
    "    \n",
    "    # insertamos las columnas de la localidad\n",
    "    df[\"ciudad\"] = ciudad\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FUNCION PARA UNIR DF, METODO DEPENDE (CONCAT, MERGE, JOIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def juntar_dfs(df_completo, df_visibilidad):\n",
    "    \n",
    "    # ahora es el turno de unir el dataframe con la información de la visibilidad con el completo\n",
    "    # en este caso el how lo ponemos como right ya que queremos que se quede con toda la info que en la segunda tabla que le pasamos que es la que tiene toda la información\n",
    "    df = pd.merge(df_completo , df_astro , on=['fecha', \"timepoint\", \"ciudad\"], how = \"right\")\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FUNCION CHEQUEANDO LOS DATOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chequear_datos(df): \n",
    "    \n",
    "    print(\"Las columnas son:\", \"\\n\")\n",
    "    print(list(df.columns))\n",
    "    print(\"-----------------------------------------\")\n",
    "    \n",
    "    print(\"Los tipos de datos que tenemos son:\", \"\\n\")\n",
    "    print(df.dtypes)\n",
    "    print(\"-----------------------------------------\")\n",
    "    \n",
    "    print(\"El porcentaje de nulos:\", \"\\n\")\n",
    "    print((df.isnull().sum() / df.shape[0]) *  100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FUNCION LIMPIANDO Y GUARDANDO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_dataframe(df, lista_columnas = []): \n",
    "    \n",
    "    #convertimos la fecha a datetime\n",
    "    df[\"fecha\"] = pd.to_datetime(df[\"fecha\"])\n",
    "    \n",
    "    # reemplazamos los nulos de las columnas por la media\n",
    "     # lista de columnas en las que queremos reemplazar los nulos\n",
    "    if len(lista_columnas) != 0:\n",
    "        df[lista_columnas]=df[lista_columnas].fillna(df.median())\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # quitar % \n",
    "    df[\"rh2m\"] = df[\"rh2m\"].replace(r\"%\", \"\", regex = True)\n",
    "    \n",
    "    # guardamos los datos una vez limpios\n",
    "    df.to_pickle('../files/datos_actualizados.pkl')\n",
    "    df.to_csv('../files/datos_actualizados.csv')\n",
    "    \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.9 (default, Jun 29 2022, 11:45:57) \n[GCC 8.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
