{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "788e211b",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Carga-de-datos\" data-toc-modified-id=\"Carga-de-datos-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Carga de datos</a></span><ul class=\"toc-item\"><li><span><a href=\"#pd.read_csv()\" data-toc-modified-id=\"pd.read_csv()-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span><code>pd.read_csv()</code></a></span></li><li><span><a href=\"#pd.read_excel()\" data-toc-modified-id=\"pd.read_excel()-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span><code>pd.read_excel()</code></a></span></li><li><span><a href=\"#pd.read_json()\" data-toc-modified-id=\"pd.read_json()-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span><code>pd.read_json()</code></a></span></li><li><span><a href=\"#pd.read_clipboard()\" data-toc-modified-id=\"pd.read_clipboard()-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span><code>pd.read_clipboard()</code></a></span></li><li><span><a href=\"#pd.read_pickle()\" data-toc-modified-id=\"pd.read_pickle()-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span><code>pd.read_pickle()</code></a></span></li><li><span><a href=\"#pd.read_parquet()\" data-toc-modified-id=\"pd.read_parquet()-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span><code>pd.read_parquet()</code></a></span></li><li><span><a href=\"#pd.read_sas()\" data-toc-modified-id=\"pd.read_sas()-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span><code>pd.read_sas()</code></a></span></li><li><span><a href=\"#pd.read_spss()\" data-toc-modified-id=\"pd.read_spss()-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span><code>pd.read_spss()</code></a></span></li></ul></li><li><span><a href=\"#üìå-Nota-importante-al-leer-archivos:\" data-toc-modified-id=\"üìå-Nota-importante-al-leer-archivos:-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>üìå Nota importante al leer archivos</a></span></li><li><span><a href=\"#Guardado-de-datos\" data-toc-modified-id=\"Guardado-de-datos-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Guardado de datos</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b107551",
   "metadata": {},
   "source": [
    "Pandas nos va a permitir leer una gran multitud de ficheros con los que podremos trabajar con los m√©todos que aprenderemos en las pr√≥ximas sesiones. En este jupyter vamos a ver algunos de los m√°s usados: \n",
    "\n",
    "- csv\n",
    "- excel\n",
    "- json\n",
    "- clipboard\n",
    "- parquet\n",
    "- pickle\n",
    "- sql\n",
    "- sas\n",
    "- spss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dca908d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pero antes de empezar ya sabeis, a importar las librer√≠as que necesitaremos!!\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14de99dd",
   "metadata": {},
   "source": [
    "üö®üö®üö® **NOTA** importante antes de seguir con esta lecci√≥n. Algunos de los ficheros que necesitaremos para la lecci√≥n de hoy son muy pesados y es imposible compartirlos con vosotras por GitBook. En concreto estos datos ser√°n: \n",
    "\n",
    "- 10M.pkl\n",
    "\n",
    "- 10M.csv\n",
    "\n",
    "- 10M.parquet\n",
    "\n",
    "- airlines.sas7bdat\n",
    "\n",
    "Estos ficheros los podr√©is descargar del [este](https://drive.google.com/drive/folders/1vTvA743_9OjvIk9SX6pdTfhwijGBXlKz) link. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3404e218",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1919c5cb",
   "metadata": {},
   "source": [
    "## `pd.read_csv()` \n",
    "\n",
    "CSV es el acr√≥nimo de *Comma Separated Values* y significa valores separados por comas. De esta forma, un archivo CSV es cualquier archivo de texto en el cual los caracteres (en nuestro caso las columnas) est√°n separadas por comas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02bdf954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>country</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>date</th>\n",
       "      <th>description</th>\n",
       "      <th>company_link</th>\n",
       "      <th>experience</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Frontend Developer</td>\n",
       "      <td>mexico</td>\n",
       "      <td>Hacienda San Pablo, M√©xico, Mexico</td>\n",
       "      <td>Vox Feed</td>\n",
       "      <td>2019-08-18</td>\n",
       "      <td>Passion for building interfaces that bring the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>web developer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               title country                            location  \\\n",
       "0   1  Frontend Developer  mexico  Hacienda San Pablo, M√©xico, Mexico   \n",
       "\n",
       "    company        date                                        description  \\\n",
       "0  Vox Feed  2019-08-18  Passion for building interfaces that bring the...   \n",
       "\n",
       "  company_link  experience       keywords  \n",
       "0          NaN           2  web developer  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv = pd.read_csv(\"jobs.csv\")\n",
    "df_csv.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecd5231",
   "metadata": {},
   "source": [
    "Como la propia definici√≥n indica, nuestras columnas deben ir separadas por comas. A veces, puede ocurrir que no vengan separados por comas. Como en el ejemplo que vemos a continuaci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dee4f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provincia;municipio;estacion;magnitud;punto_muestreo;ano;mes;dia;h01;v01;h02;v02;h03;v03;h04;v04;h05;v05;h06;v06;h07;v07;h08;v08;h09;v09;h10;v10;h11;v11;h12;v12;h13;v13;h14;v14;h15;v15;h16;v16;h17;v17;h18;v18;h19;v19;h20;v20;h21;v21;h22;v22;h23;v23;h24;v24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28;102;1;1;28102001_1_38;2022;1;30;3;T;3;T;3;T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  provincia;municipio;estacion;magnitud;punto_muestreo;ano;mes;dia;h01;v01;h02;v02;h03;v03;h04;v04;h05;v05;h06;v06;h07;v07;h08;v08;h09;v09;h10;v10;h11;v11;h12;v12;h13;v13;h14;v14;h15;v15;h16;v16;h17;v17;h18;v18;h19;v19;h20;v20;h21;v21;h22;v22;h23;v23;h24;v24\n",
       "0  28;102;1;1;28102001_1_38;2022;1;30;3;T;3;T;3;T...                                                                                                                                                                                                              "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv2 = pd.read_csv(\"aire.csv\")\n",
    "df_csv2.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d58c5a0",
   "metadata": {},
   "source": [
    "Oh oh... Algo ha salido mal... Si nos fijamos nuestras columnas est√°n separadas por `;`. ¬øC√≥mo podemos solucionar esto? \n",
    "\n",
    "> Usando el par√°metro `sep` de `pd.read_csv` donde tendremos que especificar por qu√© est√°n separadas mis columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebe52343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provincia</th>\n",
       "      <th>municipio</th>\n",
       "      <th>estacion</th>\n",
       "      <th>magnitud</th>\n",
       "      <th>punto_muestreo</th>\n",
       "      <th>ano</th>\n",
       "      <th>mes</th>\n",
       "      <th>dia</th>\n",
       "      <th>h01</th>\n",
       "      <th>v01</th>\n",
       "      <th>...</th>\n",
       "      <th>h20</th>\n",
       "      <th>v20</th>\n",
       "      <th>h21</th>\n",
       "      <th>v21</th>\n",
       "      <th>h22</th>\n",
       "      <th>v22</th>\n",
       "      <th>h23</th>\n",
       "      <th>v23</th>\n",
       "      <th>h24</th>\n",
       "      <th>v24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28102001_1_38</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>3.0</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   provincia  municipio  estacion  magnitud punto_muestreo   ano  mes  dia  \\\n",
       "0         28        102         1         1  28102001_1_38  2022    1   30   \n",
       "\n",
       "   h01 v01  ...  h20 v20  h21 v21  h22 v22  h23 v23  h24 v24  \n",
       "0  3.0   T  ...  NaN   N  NaN   N  NaN   N  NaN   N  NaN   N  \n",
       "\n",
       "[1 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# en este caso esta separado por ; \n",
    "\n",
    "df_csv2_1 = pd.read_csv(\"aire.csv\", sep = \";\")\n",
    "df_csv2_1.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a9b1ba",
   "metadata": {},
   "source": [
    "## `pd.read_excel()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c3f57f",
   "metadata": {},
   "source": [
    "En este caso abriremos ficheros con extensiones `xls` o `xlsx`. Estos son los documentos de salida de una hoja de c√°lculo de Excel. \n",
    "\n",
    "Los archivos de Excel pueden tener dos extensiones `xls` o `xlsx`, que un archivo tenga una extensi√≥n u otra depende de la versi√≥n de Excel. Versiones anteriores al 2007 ser√°n `xls` y posteriores ser√°n `xlsx`. \n",
    "\n",
    "Independientemente de la extensi√≥n, todos archivos de tipo Excel se abren en Pandas con el m√©todo `pd.read_excel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae3ef902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>espacio_prot_categoria</th>\n",
       "      <th>espacio_prot_figura</th>\n",
       "      <th>espacio_prot_nombre</th>\n",
       "      <th>espacio_prot_superficie_ha</th>\n",
       "      <th>espacio_prot_fecha_declaracion</th>\n",
       "      <th>espacio_prot_normativa</th>\n",
       "      <th>espacio_prot_informacion_web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>√Åreas protegidas por instrumentos internacionales</td>\n",
       "      <td>Reserva de la Biosfera</td>\n",
       "      <td>Cuencas Altas de los r√≠os Manzanares, Lozoya y...</td>\n",
       "      <td>105655.000</td>\n",
       "      <td>1992-11-09</td>\n",
       "      <td>Normativa √Åreas protegidas por instrumentos in...</td>\n",
       "      <td>Reserva de la Biosfera Cuencas Altas de los r√≠...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>√Åreas protegidas por instrumentos internacionales</td>\n",
       "      <td>Reserva de la Biosfera</td>\n",
       "      <td>Sierra del Rinc√≥n</td>\n",
       "      <td>15231.000</td>\n",
       "      <td>2005-06-29</td>\n",
       "      <td>Normativa √Åreas protegidas por instrumentos in...</td>\n",
       "      <td>Reserva de la Biosfera Sierra del Rinc√≥n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>√Åreas protegidas por instrumentos internacionales</td>\n",
       "      <td>Humedal de Importancia Internacional (RAMSAR)</td>\n",
       "      <td>Humedales del Macizo de Pe√±alara</td>\n",
       "      <td>487.198</td>\n",
       "      <td>2005-12-16</td>\n",
       "      <td>Normativa √Åreas protegidas por instrumentos in...</td>\n",
       "      <td>Humedales Ramsar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Espacios Protegidos Red Natura 2000</td>\n",
       "      <td>Zona de Especial Protecci√≥n para las Aves</td>\n",
       "      <td>Monte de El Pardo</td>\n",
       "      <td>15298.670</td>\n",
       "      <td>1988-02-01</td>\n",
       "      <td>Normativa Espacios Protegidos Red Natura 2000</td>\n",
       "      <td>Espacios protegidos Red Natura 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Espacios Protegidos Red Natura 2000</td>\n",
       "      <td>Zona de Especial Protecci√≥n para las Aves</td>\n",
       "      <td>Soto de Vi√±uelas</td>\n",
       "      <td>3071.890</td>\n",
       "      <td>1988-02-01</td>\n",
       "      <td>Normativa Espacios Protegidos Red Natura 2000</td>\n",
       "      <td>Espacios protegidos Red Natura 2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              espacio_prot_categoria  \\\n",
       "0  √Åreas protegidas por instrumentos internacionales   \n",
       "1  √Åreas protegidas por instrumentos internacionales   \n",
       "2  √Åreas protegidas por instrumentos internacionales   \n",
       "3                Espacios Protegidos Red Natura 2000   \n",
       "4                Espacios Protegidos Red Natura 2000   \n",
       "\n",
       "                             espacio_prot_figura  \\\n",
       "0                         Reserva de la Biosfera   \n",
       "1                         Reserva de la Biosfera   \n",
       "2  Humedal de Importancia Internacional (RAMSAR)   \n",
       "3      Zona de Especial Protecci√≥n para las Aves   \n",
       "4      Zona de Especial Protecci√≥n para las Aves   \n",
       "\n",
       "                                 espacio_prot_nombre  \\\n",
       "0  Cuencas Altas de los r√≠os Manzanares, Lozoya y...   \n",
       "1                                  Sierra del Rinc√≥n   \n",
       "2                  Humedales del Macizo de Pe√±alara    \n",
       "3                                  Monte de El Pardo   \n",
       "4                                   Soto de Vi√±uelas   \n",
       "\n",
       "   espacio_prot_superficie_ha espacio_prot_fecha_declaracion  \\\n",
       "0                  105655.000                     1992-11-09   \n",
       "1                   15231.000                     2005-06-29   \n",
       "2                     487.198                     2005-12-16   \n",
       "3                   15298.670                     1988-02-01   \n",
       "4                    3071.890                     1988-02-01   \n",
       "\n",
       "                              espacio_prot_normativa  \\\n",
       "0  Normativa √Åreas protegidas por instrumentos in...   \n",
       "1  Normativa √Åreas protegidas por instrumentos in...   \n",
       "2  Normativa √Åreas protegidas por instrumentos in...   \n",
       "3      Normativa Espacios Protegidos Red Natura 2000   \n",
       "4      Normativa Espacios Protegidos Red Natura 2000   \n",
       "\n",
       "                        espacio_prot_informacion_web  \n",
       "0  Reserva de la Biosfera Cuencas Altas de los r√≠...  \n",
       "1           Reserva de la Biosfera Sierra del Rinc√≥n  \n",
       "2                                   Humedales Ramsar  \n",
       "3                Espacios protegidos Red Natura 2000  \n",
       "4                Espacios protegidos Red Natura 2000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xlsx = pd.read_excel(\"espacios_protegidos.xlsx\")\n",
    "df_xlsx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0d8bf5",
   "metadata": {},
   "source": [
    "üö®‚ö†Ô∏è **SI OS SALE UN ERROR SIMILAR A ESTE:**\n",
    "\n",
    "```\n",
    "ImportError: Missing optional dependency 'openpyxl'. Use pip or conda to install openpyxl.\n",
    "```\n",
    "\n",
    "**DON'T PANIC!!!** Lo √∫nico que tendre√≠s que hacer es importaros `openpyxl`. ¬øC√≥mo? \n",
    "\n",
    "- Nos vamos a la terminal y ejecutamos el siguiente c√≥digo: \n",
    "\n",
    "```\n",
    "pip3 install openpyxl\n",
    "```\n",
    "\n",
    "o \n",
    "\n",
    "```\n",
    "pip install openpyxl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a04714",
   "metadata": {},
   "source": [
    "## `pd.read_json()` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f546b6e",
   "metadata": {},
   "source": [
    "Un archivo json (acr√≥nimo de *JavaScript Object Notation*) es un formato para guardar e intercambiar de forma estructurada (principalmente lo hace con una estructura de diccionario) y se utiliza principalmente para transferir datos de un servidor a un cliente. \n",
    "\n",
    "El archivo es b√°sicamente una alternativa m√°s simple y liviana al XML (Lenguaje de marcado extenso, por sus siglas en ingl√©s) que cuenta con funciones similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e9c299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 23476.42, 'res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 1927.25, 'resi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 25333.54, 'res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 22060.07, 'res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'residuos_pelig_cantidad_ton': 13109.74, 'res...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data\n",
       "0  {'residuos_pelig_cantidad_ton': 23476.42, 'res...\n",
       "1  {'residuos_pelig_cantidad_ton': 1927.25, 'resi...\n",
       "2  {'residuos_pelig_cantidad_ton': 25333.54, 'res...\n",
       "3  {'residuos_pelig_cantidad_ton': 22060.07, 'res...\n",
       "4  {'residuos_pelig_cantidad_ton': 13109.74, 'res..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_json = pd.read_json(\"residuos.json\")\n",
    "df_json.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82404269",
   "metadata": {},
   "source": [
    "Pero esto no hay quien lo lea! Pero no os preocupeis, es muy f√°cil de convertir a algo m√°s humano: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d16653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>residuos_pelig_cantidad_ton</th>\n",
       "      <th>residuos_pelig_a√±o</th>\n",
       "      <th>residuos_pelig_opcion_gestion</th>\n",
       "      <th>residuos_pelig_tratamiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23476.42</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reciclado</td>\n",
       "      <td>Recuperaci√≥n de disolventes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1927.25</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reciclado</td>\n",
       "      <td>Recuperaci√≥n de metales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25333.54</td>\n",
       "      <td>2012</td>\n",
       "      <td>Reciclado</td>\n",
       "      <td>Regeneraci√≥n de aceite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22060.07</td>\n",
       "      <td>2012</td>\n",
       "      <td>Tratamiento previo a otras formas de valorizaci√≥n</td>\n",
       "      <td>Trituraci√≥n previa a valorizaci√≥n de bater√≠as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13109.74</td>\n",
       "      <td>2012</td>\n",
       "      <td>Tratamiento previo a otras formas de valorizaci√≥n</td>\n",
       "      <td>Operaciones previas a valorizaci√≥n de RAEE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   residuos_pelig_cantidad_ton  residuos_pelig_a√±o  \\\n",
       "0                     23476.42                2012   \n",
       "1                      1927.25                2012   \n",
       "2                     25333.54                2012   \n",
       "3                     22060.07                2012   \n",
       "4                     13109.74                2012   \n",
       "\n",
       "                       residuos_pelig_opcion_gestion  \\\n",
       "0                                          Reciclado   \n",
       "1                                          Reciclado   \n",
       "2                                          Reciclado   \n",
       "3  Tratamiento previo a otras formas de valorizaci√≥n   \n",
       "4  Tratamiento previo a otras formas de valorizaci√≥n   \n",
       "\n",
       "                      residuos_pelig_tratamiento  \n",
       "0                    Recuperaci√≥n de disolventes  \n",
       "1                        Recuperaci√≥n de metales  \n",
       "2                         Regeneraci√≥n de aceite  \n",
       "3  Trituraci√≥n previa a valorizaci√≥n de bater√≠as  \n",
       "4     Operaciones previas a valorizaci√≥n de RAEE  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# este c√≥digo no es necesario que lo entendamos ahora, m√°s adelante seg√∫n avancen las lecciones lo iremos entendiendo mejor!\n",
    "df_json2 = df_json['data'].apply(pd.Series)\n",
    "df_json2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676aad0c",
   "metadata": {},
   "source": [
    "## `pd.read_clipboard()`\n",
    "\n",
    "<!-- Nos va a permitir leer el texto del portapapeles y lo pasa a `read_csv`. -->\n",
    "Este m√©todo crea un DataFrame a partir de los datos copiados en el portapapeles. Lee el texto del portapapeles y lo pasa a `read_csv()` que luego devuelve un objeto DataFrame analizado.\n",
    "\n",
    "[Aqu√≠](https://towardsdatascience.com/from-clipboard-to-dataframe-with-pandas-6c212b1d7ed8) teneis un art√≠culo muy interesante para entender esta forma de abrir ficheros \n",
    "\n",
    "Veamos paso a paso como funciona: \n",
    "\n",
    "1Ô∏è‚É£ Abrimos un excel y copiamos su contenido (pod√©is elegir cualquier excel que teng√°is en vuestro ordenador)\n",
    "\n",
    "2Ô∏è‚É£ Vamos a nuestro jupyter y ejecutamos la siguiente l√≠nea de c√≥digo: \n",
    "\n",
    "```python\n",
    "df_clip = pd.read_clipboard()\n",
    "```\n",
    "\n",
    "El par√°metro `sep` nos servir√° para especificar por que est√°n separadas cada fila y columna de nuestra tabla. En nuestro caso est√°n separados por tabulaciones que lo pondremos como `\\t`. En caso de que sea salto de p√°gina lo haremos de la siguiente forma `\\n`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2743a0fd",
   "metadata": {},
   "source": [
    "Si no especificamos el separador por defecto ser√° (\\s+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37d10bee",
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2786/2428378332.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_clipboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_clipboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_clipboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/clipboards.py\u001b[0m in \u001b[0;36mread_clipboard\u001b[0;34m(sep, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         )\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_dtype_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "df_clipboard = pd.read_clipboard(sep='\\t')\n",
    "df_clipboard.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ee3203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo mismo podemos hacer con un csv\n",
    "\n",
    "df_clipboard2 = pd.read_clipboard()\n",
    "df_clipboard2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a46028",
   "metadata": {},
   "source": [
    "üö® Tambi√©n lo podremos hacer datos de p√°ginas webs üîù!!! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086ecbfa",
   "metadata": {},
   "source": [
    "## `pd.read_pickle()` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37872443",
   "metadata": {},
   "source": [
    "Pickle (acr√≥nimo de *Python Pickle Format*) que fue desarrollado por Python. \n",
    "\n",
    "¬øQu√© es Pickle exactamente?\n",
    "\n",
    "En Python, puede usar el pickle m√≥dulo para serializar objetos y guardarlos en un archivo. \n",
    "\n",
    "Pickle tiene una gran ventaja sobre otros formatos: puede usarlo para almacenar cualquier objeto de Python, como diccionarios, pandas, arrays, etc. Una de las funcionalidades m√°s utilizadas es guardar los modelos de *machine learning*. De esa manera, no tiene que volver a capacitar al modelo cada vez que ejecuta el script.\n",
    "\n",
    "Tambi√©n se puede usar Pickle para almacenar matrices Numpy. Es una soluci√≥n obvia para establecer puntos de control de alg√∫n tipo en su c√≥digo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea3bbf",
   "metadata": {},
   "source": [
    "¬øC√≥mo trabajar con Pickle en Python? üëáüèΩ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2a9a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo primero que vamos a hacer es crearnos un dataframe\n",
    "\n",
    "df_size = 10000\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'a': np.random.rand(df_size),\n",
    "    'b': np.random.rand(df_size),\n",
    "    'c': np.random.rand(df_size),\n",
    "    'd': np.random.rand(df_size),\n",
    "    'e': np.random.rand(df_size)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71fc647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054011</td>\n",
       "      <td>0.124898</td>\n",
       "      <td>0.600285</td>\n",
       "      <td>0.573799</td>\n",
       "      <td>0.154877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.991741</td>\n",
       "      <td>0.589448</td>\n",
       "      <td>0.036163</td>\n",
       "      <td>0.092155</td>\n",
       "      <td>0.180962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.097552</td>\n",
       "      <td>0.130503</td>\n",
       "      <td>0.022758</td>\n",
       "      <td>0.072998</td>\n",
       "      <td>0.117369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.611345</td>\n",
       "      <td>0.202813</td>\n",
       "      <td>0.751257</td>\n",
       "      <td>0.229999</td>\n",
       "      <td>0.562712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.679155</td>\n",
       "      <td>0.407800</td>\n",
       "      <td>0.745477</td>\n",
       "      <td>0.337571</td>\n",
       "      <td>0.088514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b         c         d         e\n",
       "0  0.054011  0.124898  0.600285  0.573799  0.154877\n",
       "1  0.991741  0.589448  0.036163  0.092155  0.180962\n",
       "2  0.097552  0.130503  0.022758  0.072998  0.117369\n",
       "3  0.611345  0.202813  0.751257  0.229999  0.562712\n",
       "4  0.679155  0.407800  0.745477  0.337571  0.088514"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fb431d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ¬µs, sys: 0 ns, total: 4 ¬µs\n",
      "Wall time: 8.82 ¬µs\n"
     ]
    }
   ],
   "source": [
    "# guardemoslo localmente \n",
    "%time # comando m√°gico que nos devuelve el tiempo que tarda en ejecutarse nuestro c√≥digo\n",
    "\n",
    "with open('10M.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdcca84",
   "metadata": {},
   "source": [
    "Si ahora vamos a nuestra carpeta veremos que tenemos un nuevo fichero que se llama `10M.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e9a19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ¬µs, sys: 1 ¬µs, total: 5 ¬µs\n",
      "Wall time: 8.82 ¬µs\n"
     ]
    }
   ],
   "source": [
    "# lo guardaremos tambi√©n como csv para ver que se carga m√°s r√°pido\n",
    "%time\n",
    "df.to_csv('10M.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc27a6d4",
   "metadata": {},
   "source": [
    "**CSV frente a Pickle: ¬øcu√°l deber√≠a usar?**\n",
    "\n",
    "Responder esta pregunta no es tan f√°cil como parece. Claro, los CSV brindan privilegios de visualizaci√≥n y edici√≥n, ya que cualquiera puede abrirlos. Eso tambi√©n podr√≠a considerarse una desventaja, por razones obvias. Adem√°s, no puede guardar modelos de aprendizaje autom√°tico en un archivo CSV.\n",
    "\n",
    "A√∫n as√≠, comparemos los dos en tama√±o de archivo, tiempos de lectura y escritura.\n",
    "\n",
    "- pickle es mucho m√°s r√°pido que el csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbb83f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 ¬µs, sys: 1 ¬µs, total: 3 ¬µs\n",
      "Wall time: 5.96 ¬µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054011</td>\n",
       "      <td>0.124898</td>\n",
       "      <td>0.600285</td>\n",
       "      <td>0.573799</td>\n",
       "      <td>0.154877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.991741</td>\n",
       "      <td>0.589448</td>\n",
       "      <td>0.036163</td>\n",
       "      <td>0.092155</td>\n",
       "      <td>0.180962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b         c         d         e\n",
       "0  0.054011  0.124898  0.600285  0.573799  0.154877\n",
       "1  0.991741  0.589448  0.036163  0.092155  0.180962"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "pd.read_pickle(\"10M.pkl\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a6363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 ¬µs, sys: 0 ns, total: 3 ¬µs\n",
      "Wall time: 5.96 ¬µs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054011</td>\n",
       "      <td>0.124898</td>\n",
       "      <td>0.600285</td>\n",
       "      <td>0.573799</td>\n",
       "      <td>0.154877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.991741</td>\n",
       "      <td>0.589448</td>\n",
       "      <td>0.036163</td>\n",
       "      <td>0.092155</td>\n",
       "      <td>0.180962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b         c         d         e\n",
       "0  0.054011  0.124898  0.600285  0.573799  0.154877\n",
       "1  0.991741  0.589448  0.036163  0.092155  0.180962"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "pd.read_csv(\"10M.csv\", index_col = 0).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b8246",
   "metadata": {},
   "source": [
    "Aunque parece poco, el pickle se ha cargado mucho m√°s r√°pido que el csv. Imaginad como se puede notar esto cuando tengamos millones de datos! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f6b06c",
   "metadata": {},
   "source": [
    "## `pd.read_parquet()`\n",
    "\n",
    "Los formatos de archivo para el intercambio de datos m√°s populares actualmente son CSV y Microsoft Excel. Este tipo de archivos pueden ser poco eficientes a la hora trabajar con grandes conjuntos de datos.\n",
    "\n",
    "Como hemos visto CSV es un formato basado en archivos de texto plano, lo que permite su edici√≥n con cualquier editor de texto, sin la necesidad de emplear un programa espec√≠fico. Aunque esto tambi√©n se traduce en archivos de gran tama√±o y cuyo proceso es lento. \n",
    "\n",
    "Por otro lado, Microsoft Excel es un formato dise√±ado para trabajar con hojas de c√°lculo.\n",
    "\n",
    "Actualmente, para poder trabajar de forma eficiente con grandes conjuntos de datos, se han dise√±ado nuevos formatos como Parquet que ofrece archivos m√°s peque√±os, lo que ofrece importantes ahorros a la hora de almacenar los datos, y cuyas operaciones de lectura y escritura son tambi√©n m√°s r√°pidas, lo que reduce el tiempo de procesado.\n",
    "\n",
    "Apache Parquet es un formato de archivo para el almacenamiento de datos orientado a columnas de c√≥digo abierto del ecosistema Apache Hadoop. Por lo que es compatible con la mayor√≠a de *frameworks* para el procesado de datos. En este formato, los valores de cada columna se almacenan f√≠sicamente en posiciones contiguas, lo que consigue que la compresi√≥n de los datos sea m√°s eficiente al ser los datos contiguos similares. Permitiendo adem√°s usar diferentes t√©cnicas de compresi√≥n para cada columna, pudiendo adaptar esta al tipo de dato.\n",
    "\n",
    "**Parquet en Pandas**\n",
    "\n",
    "Pandas cuenta con herramientas para trabajar con archivos Parquet, por lo que no es necesario importar ning√∫n paquete adicional. Para importar archivos Parquet en objetos *DataFrame* de Pandas se puede recurrir a la funci√≥n `read_parquet()`, la cual funciona de manera similar a otras funciones `como read_csv()`. Adem√°s de esto los objetos DataFrame cuenta con la propiedad `to_parquet()`, con la que es posible volcar cualquier conjunto de datos en un archivo Parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57326bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ¬µs, sys: 1e+03 ns, total: 5 ¬µs\n",
      "Wall time: 11.7 ¬µs\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_286/2291350893.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'10M.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0mAny\u001b[0m \u001b[0madditional\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0mare\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 ).fs\n\u001b[1;32m    343\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                 parquet_kwargs[\"open_with\"] = lambda path, _: fsspec.open(\n\u001b[0m\u001b[1;32m    345\u001b[0m                     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage_options\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 ).open()\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/fastparquet/api.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fn, verify, open_with, root, sep, fs, pandas_nulls, dtypes)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# file-like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_scheme\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'simple'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'empty'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 raise ValueError('Cannot use file-like input '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/fastparquet/api.py\u001b[0m in \u001b[0;36m_parse_header\u001b[0;34m(self, f, verify)\u001b[0m\n\u001b[1;32m    212\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb'PAR1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_head_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhead_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAssertionError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 22] Invalid argument"
     ]
    }
   ],
   "source": [
    "%time\n",
    "pd.read_parquet('10M.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89854b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastparquet in /home/natig/anaconda3/lib/python3.9/site-packages (2022.11.0)\n",
      "Requirement already satisfied: packaging in /home/natig/anaconda3/lib/python3.9/site-packages (from fastparquet) (21.0)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /home/natig/anaconda3/lib/python3.9/site-packages (from fastparquet) (1.5.2)\n",
      "Requirement already satisfied: fsspec in /home/natig/anaconda3/lib/python3.9/site-packages (from fastparquet) (2021.8.1)\n",
      "Requirement already satisfied: cramjam>=2.3 in /home/natig/anaconda3/lib/python3.9/site-packages (from fastparquet) (2.6.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/natig/anaconda3/lib/python3.9/site-packages (from fastparquet) (1.20.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/natig/anaconda3/lib/python3.9/site-packages (from pandas>=1.5.0->fastparquet) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/natig/anaconda3/lib/python3.9/site-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/natig/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/natig/anaconda3/lib/python3.9/site-packages (from packaging->fastparquet) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "#!pip install pyarrow\n",
    "#!pip install fastparquet\n",
    "\n",
    "#!pip3 install --upgrade pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc118dd",
   "metadata": {},
   "source": [
    "**Diferencias entre `csv`, `pickle` y `parquet`**\n",
    "\n",
    "- `CSV`\n",
    "\n",
    "‚úÖ lectura humana  \n",
    "‚úÖ en todas las plataformas  \n",
    "‚õî m√°s lento  \n",
    "‚õî m√°s espacio en disco  \n",
    "‚õî no conserva los tipos en algunos casos  \n",
    "\n",
    "\n",
    "- `PICKLE`\n",
    "\n",
    "‚úÖ guardado/carga r√°pida  \n",
    "‚úÖ menos espacio en disco  \n",
    "‚õî no es legible para las personas  \n",
    "‚õî s√≥lo para python  \n",
    "\n",
    "- `PARQUET`: \n",
    "\n",
    "‚úÖ guardado/carga r√°pida  \n",
    "‚úÖ menos espacio en disco que pickle  \n",
    "‚úÖ suportado por muchas plataformas  \n",
    "‚õî es menos legible para los humanos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f335db5c",
   "metadata": {},
   "source": [
    "## `pd.read_sas()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9f1387",
   "metadata": {},
   "source": [
    "Lee archivos SAS almacenados en formato XPORT o SAS7BDAT.\n",
    "\n",
    "SAS es uno de los sistemas de an√°lisis avanzados m√°s populares, utilizado por muchas grandes empresas desde hace d√©cadas. Si queremos realizar alg√∫n an√°lisis utilizando un conjunto de datos SAS existente (un archivo de datos en SAS), podemos leer en Python utilizando la funci√≥n `read_sas`.\n",
    "\n",
    "`read_sas()` toma unos pocos argumentos (la mayor√≠a de ellos viene con valores predefinidos que puedes alterar si es necesario). El √∫nico obligatorio es `file_path`. \n",
    "\n",
    "La sintaxis con los par√°metros m√°s importantes es: \n",
    "\n",
    "```python\n",
    "pd.read_sas(nombre_fichero, format=None)\n",
    "```\n",
    "\n",
    "Donde:\n",
    "\n",
    "- `nombre_fichero`: el nombre del fichero o el path al fichero. \n",
    "\n",
    "\n",
    "- `format`: por defecto None. \n",
    "\n",
    "    - Si es None, el formato del archivo se deduce de la extensi√≥n del mismo. \n",
    "    \n",
    "    - Si es 'xport' o 'sas7bdat', utiliza el formato correspondiente.\n",
    "\n",
    "    \n",
    "\n",
    "[Aqu√≠](https://haven.tidyverse.org/reference/read_sas.html) ten√©is m√°s informaci√≥n sobre este m√©todo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7469228b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'FilePath' from 'pandas._typing' (/home/natig/anaconda3/lib/python3.9/site-packages/pandas/_typing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_286/1441388137.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'airline.sas7bdat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sas7bdat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/sas/sasreader.py\u001b[0m in \u001b[0;36mread_sas\u001b[0;34m(filepath_or_buffer, format, index, encoding, chunksize, iterator)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0;34mf\"unable to infer format of SAS file from filename: {repr(fname)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             )\n\u001b[0;32m--> 146\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mReaderBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"xport\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/sas/sas7bdat.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m from pandas._typing import (\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mCompressionOptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mFilePath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'FilePath' from 'pandas._typing' (/home/natig/anaconda3/lib/python3.9/site-packages/pandas/_typing.py)"
     ]
    }
   ],
   "source": [
    "pd.read_sas('airline.sas7bdat', format = 'sas7bdat').head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258b7e4f",
   "metadata": {},
   "source": [
    "## `pd.read_spss()`\n",
    "\n",
    "SPSS es un formato que ofrece IBM para un an√°lisis completo. Es el acr√≥nimo de Producto de Estad√≠stica y Soluci√≥n de Servicio. SPSS se utiliza para una amplia gama de an√°lisis estad√≠sticos, como las estad√≠sticas descriptivas (por ejemplo medias, frecuencias), las estad√≠sticas bivariadas (por ejemplo an√°lisis de la varianza, prueba t), regresi√≥n, el an√°lisis de factores, y la representaci√≥n gr√°fica de los datos.\n",
    "\n",
    "\n",
    "Este tipo de archivos es com√∫n en el √°mbito de la investigaci√≥n de mercados. A menudo √©stos est√°n disponibles como archivos SAV o SPSS. SPSS es ideal para el an√°lisis estad√≠stico de datos de encuestas porque las variables, las etiquetas de las variables, los valores y las etiquetas de los valores est√°n integrados en un conjunto de datos.\n",
    "\n",
    "Desafortunadamente, SPSS es lento en sets de datos grandes y el sistema de macros para la automatizaci√≥n no es intuitivo y ofrece s√≥lo unas pocas opciones en comparaci√≥n con Python. Por lo tanto, no ser√° un tipo de archivo que nos encontremos habitualmente. \n",
    "\n",
    "`read_spss()` lee los datos de un archivo almacenado en formato SPSS `*.sav`. \n",
    "\n",
    "Devuelve un *DataFrame* y **nunca** convierte las variables de tipo *string* en factores. Tambi√©n prepara las etiquetas de los valores/variables de SPSS para trabajar con las funciones `val_lab`/`var_lab`. \n",
    "\n",
    "Ignora los valores nulos. \n",
    "\n",
    "Su sintaxis: \n",
    "\n",
    "```python\n",
    "pd.read_spss(path, usecols=None, convert_categoricals=True)\n",
    "```\n",
    "\n",
    "Donde : \n",
    "\n",
    "- `path`: *string* ruta a nuestro archivo. \n",
    "\n",
    "- `usecols`: lista, opcional. Devuelve un subconjunto de las columnas. Si es `None`, devuelve todas las columnas.\n",
    "\n",
    "- `convert_categoricals`: booleano, por defecto es `True`. Convierte las columnas categ√≥ricas en `pd.Categorical`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef78f94",
   "metadata": {},
   "source": [
    "# üìå Nota importante al leer archivos: \n",
    "\n",
    "Varias cosas pueden ir mal cuando se importan los datos a Pandas. Algunos de ellos son inmediatamente obvios; otros s√≥lo aparecen m√°s tarde, en formas confusas.\n",
    "\n",
    "En este apartado veremos uno de los problemas m√°s comunes al cargar datos en Pandas - la codificaci√≥n de texto.\n",
    "\n",
    "Las codificaciones de texto son conjuntos espec√≠ficos de reglas para mapear desde cadenas de bytes binarios sin procesar hasta caracteres que componen el texto legible por humanos. Python tiene soporte integrado para una lista de codificaciones est√°ndar.\n",
    "\n",
    "Las discrepancias en la codificaci√≥n de caracteres son menos comunes hoy en d√≠a, ya que UTF-8 es la codificaci√≥n de texto est√°ndar en la mayor√≠a de los lenguajes de programaci√≥n, incluido Python. Sin embargo, definitivamente sigue siendo un problema si estamos intentando leer un archivo con una codificaci√≥n diferente a la que se escribi√≥ originalmente.\n",
    "\n",
    "Otra codificaci√≥n com√∫n, pero menos √∫til, es la llamada Latin 1 o ISO-8859-1. Esta codificaci√≥n s√≥lo define formas de representar los caracteres del texto en el alfabeto latino est√°ndar. Se trata del alfabeto ingl√©s est√°ndar m√°s una serie de caracteres de otras lenguas europeas, incluidos los caracteres con acento.\n",
    "\n",
    "La funci√≥n `read_csv()` de Pandas tiene una llamada de argumento `encoding` que le permite especificar una codificaci√≥n para usar al leer un archivo. Pandas asume que el texto est√° en formato UTF-8, porque es el m√°s com√∫n.\n",
    "\n",
    "Os dejamos [aqu√≠](https://docs.python.org/3/library/codecs.html#standard-encodings) una lista con los principales tipos de *encoding* que podemos encontrarnos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5852b3c",
   "metadata": {},
   "source": [
    "# Guardado de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62096d27",
   "metadata": {},
   "source": [
    "Imaginemos ahora que hemos hecho algunos cambios en nuestro dataframe, por ejemplo quitar algunas columnas y que queremos guardar los cambios en nuestro ordenador. Pandas nos lo va a permitir para cada uno de los tipos de archivos que hemos estado viendo hasta ahora."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c064f6eb",
   "metadata": {},
   "source": [
    "`to_csv`: guardaremos el archivo en formato csv. Normalmente con especificar el directorio y el nombre del fichero ser√° suficiente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d3a8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar en csv\n",
    "\n",
    "df_csv2.to_csv(\"datos/datos_sincolumna.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d555d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar en formato de excel\n",
    "\n",
    "df_csv2.to_excel(\"datos/datos_sincolumna.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e144058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar en formato json\n",
    "\n",
    "df_csv2.to_json(\"datos/datos_sincolumna.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524773a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar en formato parquet\n",
    "\n",
    "df_csv2.to_parquet(\"datos/datos_sincolumna.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c27772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar en formato pickle\n",
    "\n",
    "df_csv2.to_pickle(\"datos/datos_sincolumna.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cccea3",
   "metadata": {},
   "source": [
    "Aqu√≠ os dejamos algo de documentaci√≥n m√°s detallada de cada uno de los m√©todos: \n",
    "\n",
    "- [to_csv](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html)\n",
    "\n",
    "- [to_excel](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_excel.html)\n",
    "\n",
    "- [to_json](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_json.html)\n",
    "\n",
    "- [to_parquet](https://pandas.pydata.org/pandas-docs/version/1.1/reference/api/pandas.DataFrame.to_parquet.html)\n",
    "\n",
    "- [to_pickle](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ebacf0c690606339d2819fda86ce84d5dc8f19bdafd30d1cf039ac39003e3ee9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
